---
title: "GCM, LOCO Subsets selection"
author: "Chenghui Zheng"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,echo=FALSE, warning=FALSE, message=FALSE}
library(MASS)
library(dplyr)
library(mvtnorm)
library(matrixcalc)
library(mlr)
library(iml)
library(ggplot2)
library(randomForest)
library(kernlab) #ksvm
library(kknn)
library(nnet)
source("C:/Users/pearl/OneDrive/Documents/Research/spring 2024 project/stored_functions_for_GCM_LOCO.R")
```
### (a) Linear Model with Independent Predictors

\[ Y_1 \sim 1.5X_1 +1.5 X_2 + 2X_3 + 2X_4 + 2X_5 + 3X_6 + 4X_7 + 5X_8 + \epsilon \]

### (b) Linear Model with Correlated Predictors

\[ Y_2 \sim 1.5X_1 +1.5 X_2 + 2X_3 + 2X_4 + 2X_5 + 3X_6 + 4X_7 + 5X_8 + \epsilon \]

Where \(X_1 \not\perp\!\!\!\perp X_2\) and \(\text{cov}(X_1, X_2) = 0, 0.5, 0.75, 0.9\) respectively.

### (c) Linear Model with Correlated Predictors and Different SNR

\[ Y_3 \sim 1.5X_1 +1.5 X_2 + 2X_3 + 2X_4 + 2X_5 + 3X_6 + 4X_7 + 5X_8 + \epsilon \]

Where \(\text{cov}(X_i, X_j) = \rho^{|i-j|}\) and \(\epsilon \sim N(0, \sigma^2)\) with \(\sigma^2 = 0.1, 0.5, 0.75, 2.1\).

### (d) Non-linear Model 

\[ Y_4 \sim 2X_1^2 + 2\cos(4X_2) + \sin(X_3) + \exp\left(X_4/3\right) + 3X_5 +X_6^3 + 5 X_7 + \max(0, X_8) \]


# GCM Subsets selection
```{r,echo=FALSE,warning=FALSE,message=FALSE}
# case a)
run_simulation_a <- function(num_simulations) {
  results_list <- list()
  
  for (i in 1:num_simulations) {
    set.seed(123)  
    
    sigma_indep <- diag(1, nrow = 20)
    data_indep <- as.data.frame(mvrnorm(n = 500, 
                                        mu = rep(0, times = 20), 
                                        Sigma = sigma_indep))
    colnames(data_indep) <- paste("X", 1:20, sep = "")
    
    # Define response y
   y1 <- 1.5*data_indep$X1 + 1.5*data_indep$X2 + 2*data_indep$X3 + 2*data_indep$X4+
          2 * data_indep$X5 + 3 * data_indep$X6 + 
          4 * data_indep$X7 + 5 * data_indep$X8 + 
          rnorm(n = 500, mean = 0, sd = 0.1)
    data_indep["y"] <- y1
    
    # Run LOCO
    data_list <- subsets_combinations(data = data_indep, target = "y",num_groups = 5, num_random = i)
    LOCO_results <- LOCO_subset(data_comb_list = data_list,full_data = data_indep, learner = "regr.lm", target = "y")
    
    # Store the results in the list
    results_list[[i]] <- LOCO_results
  }
  return(aggregate_results(results_list))
  #return(results_list)
}
```


```{r,echo=FALSE,eval=TRUE}
# rejection rate vs features
results <- run_simulation_a(100)
results$Features <- factor(results$Features, levels = paste0("X", 1:20))

 ggplot(results, aes(x = Features, y = rejection))+ geom_point(size =1) +
  geom_line(aes(group = 1), size = 0.5)+
  labs(title = 'Case a): ',
       x = 'Features',
       y = 'rejection rate') +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```



```{r, eval=FALSE,echo=FALSE,warning=FALSE}
# Accuracy vs number of combination
correct_features <-paste("X", 1:8, sep = "")
start <- proc.time()
sim_results <- run_simulation_a(100)
num_comb <- seq(1,100,3)
results <- data.frame(num_combination = numeric(0), Accuracy = numeric(0))
for (k in num_comb) {
  output <- aggregate_results(sim_results[1:k])
  accuracy <- accuracy_comp(correct_feature_list = correct_features,data = output)
  new_row <- data.frame(num_combination = k, Accuracy = accuracy)
  results <- rbind(results, new_row)
}


print( proc.time() - start)


#results_1$Features <- factor(results_1$Features, levels = paste0("X", 1:20))
ggplot(results, aes(x = num_combination, y = Accuracy)) +
  geom_point(size = 1) +
  geom_line(aes(group = 1),size=0.5)  +
  labs(title = "Case a):", x = "Number of Combinations", y = "Accuracy") +
  theme_minimal()
#+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) #+geom_hline(yintercept = 0.05, linetype = "dashed", color = "red")

```


```{r,echo=FALSE}
# case b)

run_simulation_b <- function(cor, num_simulations, Alpha = 0.05) {
  results_list <- list()
  
  for (i in 1:num_simulations) {
    set.seed(123)  
    
    sigma_indep <- diag(1, nrow = 20)
    sigma_indep[1, 2] <- cor
    sigma_indep[2, 1] <- cor
    data_indep <- as.data.frame(mvrnorm(n = 500, 
                                        mu = rep(0, times = 20), 
                                        Sigma = sigma_indep))
    colnames(data_indep) <- paste("X", 1:20, sep = "")
    
    # Define response y
    y1 <- 1.5*data_indep$X1 + 1.5*data_indep$X2 + 2*data_indep$X3 + 2*data_indep$X4+
          2 * data_indep$X5 + 3 * data_indep$X6 + 
          4 * data_indep$X7 + 5 * data_indep$X8 + 
          rnorm(n = 500, mean = 0, sd = 0.1)
    data_indep["y"] <- y1
        # Run LOCO
    data_list <- subsets_combinations(data = data_indep, target = "y",num_groups = 5, num_random = i)
    LOCO_results <- LOCO_subset(data_comb_list = data_list,full_data = data_indep, learner = "regr.lm", target = "y")
    # Store the results in the list
    results_list[[i]] <- LOCO_results
  }
  #return(results_list) 
  return(aggregate_results(results_list))
}



start <- proc.time()

correlations <- c(0, 0.5, 0.75, 0.9)
```

```{r,echo=FALSE,eval=FALSE}
# Accuracy vs num_combination
#---------------------------------------------------------
results <- data.frame(num_combination = numeric(0), Accuracy = numeric(0), Correlation = numeric(0))
num_comb <- seq(1,100,3)
for (rho in correlations) {
  sim_results <- run_simulation_b(cor = rho, num_simulations=100, Alpha = 0.05)

for (k in num_comb) {
  output <- aggregate_results(sim_results[1:k])
  accuracy <- accuracy_comp(correct_feature_list = correct_features,data = output)
  new_row <- data.frame(num_combination = k, Accuracy = accuracy, Correlation = rho)
  results <- rbind(results, new_row)
}
}
print( proc.time() - start )


results$Correlation <- as.factor(results$Correlation)
ggplot(results, aes(x = num_combination, y = Accuracy, color = Correlation)) +
  geom_point(size = 3) +
  geom_line(aes(group = Correlation), size = 1) +
  scale_color_brewer(palette = "Set1") +
  labs(title = 'Case b):',
       x = 'Number of Combinations',
       y = 'Accuracy') +
  coord_cartesian(ylim = c(0, 1)) +
  theme_minimal()

```

```{r,eval=TRUE,echo=FALSE}
# rejection rate vs features
results2 <- data.frame()
for (rho in correlations) {
  results_b <- run_simulation_b(cor = rho, num_simulations=100, Alpha = 0.05)
  
  results_b$Correlation <- rho
  
  results2 <- rbind(results2, results_b)
}
print( proc.time() - start )
#write.csv(results2, "simulation_0.01gcm_filter2.csv", row.names = FALSE)
results2$Features <- factor(results2$Features, levels = paste0("X", 1:20))
results2$Correlation <- as.factor(results2$Correlation)
 ggplot(results2, aes(x = Features, y = rejection, color = Correlation))+ geom_point(size = 3) +
  geom_line(aes(group = Correlation), size = 1) +
  scale_color_brewer(palette = "Set1")   +
  labs(title = 'Case b): ',
       x = 'Features',
       y = 'rejection rate') +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) 
#+geom_hline(yintercept = 0.05, linetype = "dashed", color = "red")
```


```{r,echo=FALSE}
# case c)
run_simulation_c <- function(snr, num_simulations, Alpha = 0.05) {
  results_list <- list()
  
  for (i in 1:num_simulations) {
    set.seed(123)  
    sigma_indep <- cplx_cov_matrix(n=20, rho=0.7)
    data_indep <- as.data.frame(mvrnorm(n = 500, 
                                        mu = rep(0, times = 20), 
                                        Sigma = sigma_indep))
    colnames(data_indep) <- paste("X", 1:20, sep = "")

    y1 <- 1.5*data_indep$X1 + 1.5*data_indep$X2 + 2*data_indep$X3 + 2*data_indep$X4+
          2 * data_indep$X5 + 3 * data_indep$X6 + 
          4 * data_indep$X7 + 5 * data_indep$X8 + 
          rnorm(n = 500, mean = 0, sd = 0.1)
    data_indep["y"] <- y1
    
    data_list <- subsets_combinations(data = data_indep, target = "y",num_groups = 5, num_random = i)
    LOCO_results <- LOCO_subset(data_comb_list = data_list,full_data = data_indep, learner = "regr.lm", target = "y")
    
    results_list[[i]] <- LOCO_results
  }
  #return(results_list)
  return(aggregate_results(results_list))
}
#------------------------------------------------------
```

```{r,eval=FALSE,echo=FALSE}
#Accuracy vs num_combination
snrs <- c(0.1, 0.5, 0.75, 2.1)
results <- data.frame(num_combination = numeric(0), Accuracy = numeric(0), snr = numeric(0))
num_comb <- seq(1,100,3)
for (snr in snrs) {
  sim_results <- run_simulation_c(snr = snr, num_simulations=100, Alpha = 0.05)

for (k in num_comb) {
  output <- aggregate_results(sim_results[1:k])
  accuracy <- accuracy_comp(correct_feature_list = correct_features,data = output)
  new_row <- data.frame(num_combination = k, Accuracy = accuracy, snr = snr)
  results <- rbind(results, new_row)
}
}
print( proc.time() - start )


results$snr <- as.factor(results$snr)
ggplot(results, aes(x = num_combination, y = Accuracy, color = snr)) +
  geom_point(size = 2) +
  geom_line(aes(group = snr), size = 1) +
  scale_color_brewer(palette = "Set1") +
  labs(title = 'Case c):',
       x = 'Number of Combinations',
       y = 'Accuracy') +
  coord_cartesian(ylim = c(0, 1)) +
  theme_minimal()

```


```{r,eval=TRUE,echo=FALSE}
# rejection rate vs features
start <- proc.time()
results3 <- data.frame()

snrs <- c(0.1, 0.5, 0.75, 2.1)


for (sigma in snrs) {
  results_c <- run_simulation_c(snr = sigma, num_simulations=100,Alpha=0.05)
  
  results_c$snr <- sigma
  
  results3 <- rbind(results3, results_c)
}
#print( proc.time() - start )
#write.csv(results3, "simulation_0.01gcm_filter3.csv", row.names = FALSE)
results3$Features <- factor(results3$Features, levels = paste0("X", 1:20))
results3$snr <- as.factor(results3$snr)
 ggplot(results3, aes(x = Features, y = rejection, color = snr))+ geom_point(size = 3) +
  geom_line(aes(group = snr), size = 1) +
  scale_color_brewer(palette = "Set1")   +
  labs(title = 'Case c): ',
       x = 'Features',
       y = 'rejection rate') +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) 
#+geom_hline(yintercept = 0.05, linetype = "dashed", color = "red")
```

```{r,echo=FALSE}
# case d) non-linear
run_simulation_d <- function(num_simulations) {
  results_list <- list()
  
  for (i in 1:num_simulations) {
    set.seed(123)
    sigma_indep <- diag(1, nrow = 20)
    data_indep <- as.data.frame(mvrnorm(n = 500, 
                                        mu = rep(0, times = 20), 
                                        Sigma = sigma_indep))
    colnames(data_indep) <- paste("X", 1:20, sep = "")

    # Define response y
    y1 <- 2*(data_indep$X1)^2 + 2*cos(4*data_indep$X2) + sin(data_indep$X3) + exp(data_indep$X4/3)+ + 3*data_indep$X5 + (data_indep$X6)^3+ 
          5 * data_indep$X7 + 
          rnorm(n = 500, mean = 0, sd = 0.1)
    data_indep["y"] <- y1
    
    # Run LOCO
    data_list <- subsets_combinations(data = data_indep, target = "y",num_groups = 5, num_random = i)
    LOCO_results <- LOCO_subset(data_comb_list = data_list,full_data = data_indep, learner = "regr.ksvm", target = "y")
    
    # Store the results in the list
    results_list[[i]] <- LOCO_results
  }
  
  return(aggregate_results(results_list))
  #return(results_list)

}

```

```{r, eval=FALSE,echo=FALSE}
#accuracy vs num_combination
start <- proc.time()
sim_results <- run_simulation_d(100)
num_comb <- seq(1,100,3)

results <- data.frame(num_combination = numeric(0), Accuracy = numeric(0))
for (k in num_comb) {
  output <- aggregate_results(sim_results[1:k])
  accuracy <- accuracy_comp(correct_feature_list = correct_features,data = output)
  new_row <- data.frame(num_combination = k, Accuracy = accuracy)
  results <- rbind(results, new_row)
}


print( proc.time() - start)

ggplot(results, aes(x = num_combination, y = Accuracy)) +
  geom_point(size = 1) +
  geom_line(aes(group = 1),size=0.5)  +
  labs(title = "Case d):", x = "Number of Combinations", y = "Accuracy") +theme_minimal()


```


```{r,eval=TRUE, echo=FALSE}
# rejection rate vs features
start <- proc.time()
results_d <- run_simulation_d(100)
print( proc.time() - start )
results_d$Features <- factor(results_d$Features, levels = paste0("X", 1:20))
ggplot(results_d, aes(x = Features, y = rejection)) +
  geom_point(size = 1) +
  geom_line(aes(group = 1),size=0.5)  +
  labs(title = "Case d):", x = "Features", y = "rejection rate") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) #+ geom_hline(yintercept = 0.05, linetype = "dashed", color = "red")
```