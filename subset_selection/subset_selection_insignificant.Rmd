---
title: "Subset Selection for Insignificant subsets"
author: "Chenghui Zheng"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,echo=FALSE, warning=FALSE, message=FALSE}
library(MASS)
library(dplyr)
library(mvtnorm)
library(matrixcalc)
library(mlr)
library(iml)
library(ggplot2)
library(randomForest)
library(kernlab) #ksvm
library(kknn)
library(nnet)
source("C:/Users/pearl/OneDrive/Documents/Research/spring 2024 project/stored_functions_for_GCM_LOCO.R")
```
### (a) Linear Model with Independent Predictors

\[ Y_1 \sim 1.5X_1 +1.5 X_2 + 2X_3 + 2X_4 + 2X_5 + 3X_6 + 4X_7 + 5X_8 + \epsilon \]

### (b) Linear Model with Correlated Predictors

\[ Y_2 \sim 1.5X_1 +1.5 X_2 + 2X_3 + 2X_4 + 2X_5 + 3X_6 + 4X_7 + 5X_8 + \epsilon \]

Where \(X_1 \not\perp\!\!\!\perp X_2\) and \(\text{cov}(X_1, X_2) = 0, 0.5, 0.75, 0.9\) respectively.

### (c) Linear Model with Correlated Predictors and Different SNR

\[ Y_3 \sim 1.5X_1 +1.5 X_2 + 2X_3 + 2X_4 + 2X_5 + 3X_6 + 4X_7 + 5X_8 + \epsilon \]

Where \(\text{cov}(X_i, X_j) = \rho^{|i-j|}\) and \(\epsilon \sim N(0, \sigma^2)\) with \(\sigma^2 = 0.1, 0.5, 0.75, 2.1\).

### (d) Non-linear Model 

\[ Y_4 \sim 2X_1^2 + 2\cos(4X_2) + \sin(X_3) + \exp\left(X_4/3\right) + 3X_5 +X_6^3 + 5 X_7 + \max(0, X_8) \]

# GCM Subsets selection(old T(n),100 simulations, each 500 instances)
```{r,echo=FALSE,warning=FALSE,message=FALSE}
# case a)
run_simulation_a <- function(num_simulations) {
  results_list <- list()
  
  for (i in 1:num_simulations) {
    set.seed(123)  
    
    sigma_indep <- diag(1, nrow = 20)
    data_indep <- as.data.frame(mvrnorm(n = 500, 
                                        mu = rep(0, times = 20), 
                                        Sigma = sigma_indep))
    colnames(data_indep) <- paste("X", 1:20, sep = "")
    
    # Define response y
   y1 <- 1.5*data_indep$X1 + 1.5*data_indep$X2 + 2*data_indep$X3 + 2*data_indep$X4+
          2 * data_indep$X5 + 3 * data_indep$X6 + 
          4 * data_indep$X7 + 5 * data_indep$X8 + 
          rnorm(n = 500, mean = 0, sd = 0.1)
    data_indep["y"] <- y1
    
    
    data_list <- within_gp_subsets_combinations(data = data_indep, sig_num_gp = 2, insig_num_gp = 3,randomization = i)
    LOCO_results <- GCM_subset_filter(data_comb_list = data_list,full_data = data_indep, learner = "regr.lm", target = "y")
    LOCO_results["classification"] <- rep(c("significant subset", "insignificant subset"), times = c(2, 3))

    
    # Store the results in the list
    results_list[[i]] <- LOCO_results
  }
  #return(aggregate_results(results_list))
  return(results_list)
}
```


```{r, eval=TRUE,echo=FALSE,warning=FALSE}
# rejection rate vs number of combination

#start <- proc.time()
sim_results <- run_simulation_a(100)
num_comb <- seq(1,100,3)
results <- data.frame()
for (k in num_comb) {
  output <- do.call(rbind, sim_results[1:k])
  summary <- output %>% group_by(classification) %>% summarise(rejection = sum(rejection), total_num_tests= n(),rejection_rate = rejection/total_num_tests)
  summary["num_combination"] = k
  results <- rbind(results, summary)
}
#print( proc.time() - start)

ggplot(results, aes(x = total_num_tests, y = rejection_rate)) +
  geom_point(size = 1) +
  geom_line(aes(group = 1),linewidth=0.5)  +
  labs(title = "Case a):", x = "Total Number of Subset Tests\n(over 100 combinations)", y = "Rejection Rate") +
  theme_minimal()+facet_wrap(~classification)
```

```{r,echo=FALSE}
# case b)

run_simulation_b <- function(cor, num_simulations, Alpha = 0.05) {
  results_list <- list()
  
  for (i in 1:num_simulations) {
    set.seed(123+i)  
    
    sigma_indep <- diag(1, nrow = 20)
    sigma_indep[1, 2] <- cor
    sigma_indep[2, 1] <- cor
    data_indep <- as.data.frame(mvrnorm(n = 500, 
                                        mu = rep(0, times = 20), 
                                        Sigma = sigma_indep))
    colnames(data_indep) <- paste("X", 1:20, sep = "")
    
    # Define response y
    y1 <- 1.5*data_indep$X1 + 1.5*data_indep$X2 + 2*data_indep$X3 + 2*data_indep$X4+
          2 * data_indep$X5 + 3 * data_indep$X6 + 
          4 * data_indep$X7 + 5 * data_indep$X8 + 
          rnorm(n = 500, mean = 0, sd = 0.1)
    data_indep["y"] <- y1
        # Run LOCO
    data_list <- within_gp_subsets_combinations(data = data_indep, sig_num_gp = 2, insig_num_gp = 3,randomization = i)
    LOCO_results <- GCM_subset_filter(data_comb_list = data_list,full_data = data_indep, learner = "regr.lm", target = "y")
    LOCO_results["classification"] <- rep(c("significant subset", "insignificant subset"), times = c(2, 3))
    
    # Store the results in the list
    results_list[[i]] <- LOCO_results
  }
  return(results_list) 
  #return(aggregate_results(results_list))
}

correlations <- c(0, 0.5, 0.75, 0.9)
```

```{r,echo=FALSE}
# rejection rate vs number of combination
results <- data.frame()
num_comb <- seq(1,100,3)
for (rho in correlations) {
  sim_results <- run_simulation_b(cor = rho, num_simulations=100, Alpha = 0.05)

for (k in num_comb) {
  output <- do.call(rbind, sim_results[1:k])
  summary <- output %>% group_by(classification) %>% summarise(rejection = sum(rejection), total_num_tests= n(),rejection_rate = rejection/total_num_tests)
  summary["num_combination"] = k
  summary["Correlation"] = rho
  results <- rbind(results, summary)
}
}

results$Correlation <- as.factor(results$Correlation)
ggplot(results, aes(x = total_num_tests, y = rejection_rate, color = Correlation)) +
  geom_point(size = 1) +
  geom_line(aes(group = Correlation), linewidth = 0.5) +
  scale_color_brewer(palette = "Set1") +
  labs(title = 'Case b):',
       x = "Total Number of Subset Tests\n(over 100 combinations)", y = "Rejection Rate") +
  coord_cartesian(ylim = c(0, 1)) +
  theme_minimal()+facet_wrap(~classification)

```

```{r,echo=FALSE}
# case c)
run_simulation_c <- function(snr, num_simulations, Alpha = 0.05) {
  results_list <- list()
  
  for (i in 1:num_simulations) {
    set.seed(123+i)  
    sigma_indep <- cplx_cov_matrix(n=20, rho=0.7)
    data_indep <- as.data.frame(mvrnorm(n = 500, 
                                        mu = rep(0, times = 20), 
                                        Sigma = sigma_indep))
    colnames(data_indep) <- paste("X", 1:20, sep = "")

    y1 <- 1.5*data_indep$X1 + 1.5*data_indep$X2 + 2*data_indep$X3 + 2*data_indep$X4+
          2 * data_indep$X5 + 3 * data_indep$X6 + 
          4 * data_indep$X7 + 5 * data_indep$X8 + 
          rnorm(n = 500, mean = 0, sd = 0.1)
    data_indep["y"] <- y1
    
    data_list <- within_gp_subsets_combinations(data = data_indep, sig_num_gp = 2, insig_num_gp = 3,randomization = i)
    LOCO_results <- GCM_subset_filter(data_comb_list = data_list,full_data = data_indep, learner = "regr.lm", target = "y")
    LOCO_results["classification"] <- rep(c("significant subset", "insignificant subset"), times = c(2, 3))
    
    results_list[[i]] <- LOCO_results
  }
  return(results_list)
  #return(aggregate_results(results_list))
}
```

```{r,echo=FALSE}
# rejection rate vs number of combination
snrs <- c(0.1, 0.5, 0.75, 2.1)
results <- data.frame()
num_comb <- seq(1,100,3)
for (sigma in snrs)  {
  sim_results <- run_simulation_c(snr = sigma, num_simulations=100, Alpha = 0.05)

for (k in num_comb) {
  output <- do.call(rbind, sim_results[1:k])
  summary <- output %>% group_by(classification) %>% summarise(rejection = sum(rejection), total_num_tests= n(),rejection_rate = rejection/total_num_tests)
  summary["num_combination"] = k
  summary["snr"] = sigma
  results <- rbind(results, summary)
}
}

results$snr <- as.factor(results$snr)
ggplot(results, aes(x = total_num_tests, y = rejection_rate, color = snr)) +
  geom_point(size = 1) +
  geom_line(aes(group = snr), linewidth = 0.5) +
  scale_color_brewer(palette = "Set1") +
  labs(title = 'Case c):',
       x = "Total Number of Subset Tests\n(over 100 combinations)", y = "Rejection Rate") +
  coord_cartesian(ylim = c(0, 1)) +
  theme_minimal()+facet_wrap(~classification)

```

```{r,echo=FALSE}
# case d) non-linear
run_simulation_d <- function(num_simulations,size = 500) {
  results_list <- list()
  
  for (i in 1:num_simulations) {
    set.seed(123)
    sigma_indep <- diag(1, nrow = 20)
    data_indep <- as.data.frame(mvrnorm(n = size, 
                                        mu = rep(0, times = 20), 
                                        Sigma = sigma_indep))
    colnames(data_indep) <- paste("X", 1:20, sep = "")

    # Define response y
    y1 <- 2*(data_indep$X1)^2 + 2*cos(4*data_indep$X2) + sin(data_indep$X3) + exp(data_indep$X4/3)+ + 3*data_indep$X5 + (data_indep$X6)^3+ 5 * data_indep$X7+pmax(0,data_indep$X8) +rnorm(n = size, mean = 0, sd = 0.1)
    data_indep["y"] <- y1
    
    # Run LOCO
    data_list <- within_gp_subsets_combinations(data = data_indep, sig_num_gp = 2, insig_num_gp = 3,randomization = i)
    LOCO_results <- GCM_subset_filter(data_comb_list = data_list,full_data = data_indep, learner = "regr.ksvm", target = "y")
    LOCO_results["classification"] <- rep(c("significant subset", "insignificant subset"), times = c(2, 3))
    
    # Store the results in the list
    results_list[[i]] <- LOCO_results
  }
  
  #return(aggregate_results(results_list))
  return(results_list)
}
```

```{r, eval=TRUE,echo=FALSE,warning=FALSE}
# rejection rate vs number of combination

#start <- proc.time()
sim_results <- run_simulation_d(100)
num_comb <- seq(1,100,3)
results <- data.frame()
for (k in num_comb) {
  output <- do.call(rbind, sim_results[1:k])
  summary <- output %>% group_by(classification) %>% summarise(rejection = sum(rejection), total_num_tests= n(),rejection_rate = rejection/total_num_tests)
  summary["num_combination"] = k
  results <- rbind(results, summary)
}
#print( proc.time() - start)

ggplot(results, aes(x = total_num_tests, y = rejection_rate)) +
  geom_point(size = 1) +
  geom_line(aes(group = 1),linewidth=0.5)  +
  labs(title = "Case d):", x = "Total Number of Subset Tests\n(over 100 combinations)", y = "Rejection Rate") +
  theme_minimal()+facet_wrap(~classification)
```
